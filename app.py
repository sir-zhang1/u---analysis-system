import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import random
from datetime import datetime, timedelta
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules
import warnings
import os
warnings.filterwarnings('ignore')

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Uå›¢å›¢æ ¡å›­å›¢è´­æ™ºèƒ½åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ›’",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 30px;
        font-weight: bold;
    }
    .sub-header {
        font-size: 1.8rem;
        color: #ff7f0e;
        margin-top: 20px;
        margin-bottom: 15px;
    }
    .insight-box {
        background-color: #e8f4fd;
        padding: 15px;
        border-left: 4px solid #1f77b4;
        margin: 10px 0;
        border-radius: 5px;
    }
    .data-source {
        background-color: #f8f9fa;
        padding: 10px;
        border-radius: 5px;
        border-left: 3px solid #28a745;
        margin: 10px 0;
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)

class DataLoader:
    """æ•°æ®åŠ è½½å™¨ç±» - ä¸“é—¨åŠ è½½çœŸå®çš„å›¢è´­æ•°æ®"""
    
    @staticmethod
    @st.cache_data
    def load_orders_data():
        """åŠ è½½è®¢å•æ•°æ®"""
        try:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
            possible_paths = [
                r"D:\ç¼–ç¨‹\Uå›¢å›¢\orders_data.csv",
                'orders_data.csv',
                './orders_data.csv', 
                'data/orders_data.csv',
                './data/orders_data.csv'
            ]
            
            df = None
            file_found = False
            
            for path in possible_paths:
                try:
                    if os.path.exists(path):
                        df = pd.read_csv(path, encoding='utf-8-sig')
                        file_found = True
                        break
                except Exception as e:
                    continue
            
            if not file_found:
                st.error("âš  æ— æ³•æ‰¾åˆ°è®¢å•æ•°æ®æ–‡ä»¶ï¼")
                st.info("ğŸ’¡ è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶ä¹‹ä¸€å­˜åœ¨ï¼š")
                for path in possible_paths:
                    st.code(path)
                return None
            
            # æ•°æ®éªŒè¯ï¼ˆé™é»˜å¤„ç†ï¼Œä¸æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯ï¼‰
            required_columns = ['è®¢å•ç¼–å·', 'ç”¨æˆ·ID', 'å•†å“åç§°', 'å•ä»·', 'è´­ä¹°æ•°é‡', 'è®¢å•é‡‘é¢', 'ä¸‹å•æ—¶é—´', 'æ ¡åŒº', 'è®¢å•çŠ¶æ€']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                st.error(f"âš  æ•°æ®æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
                return None
            
            # æ•°æ®ç±»å‹è½¬æ¢å’Œæ¸…ç†
            try:
                df['ä¸‹å•æ—¶é—´'] = pd.to_datetime(df['ä¸‹å•æ—¶é—´'])
                df['å•ä»·'] = pd.to_numeric(df['å•ä»·'], errors='coerce')
                df['è´­ä¹°æ•°é‡'] = pd.to_numeric(df['è´­ä¹°æ•°é‡'], errors='coerce')
                df['è®¢å•é‡‘é¢'] = pd.to_numeric(df['è®¢å•é‡‘é¢'], errors='coerce')
            except Exception as e:
                st.error(f"âš  æ•°æ®ç±»å‹è½¬æ¢å¤±è´¥: {e}")
                return None
            
            # æ·»åŠ åˆ†ææ‰€éœ€çš„æ—¶é—´ç‰¹å¾
            df['ä¸‹å•å°æ—¶'] = df['ä¸‹å•æ—¶é—´'].dt.hour
            df['æ˜ŸæœŸå‡ '] = df['ä¸‹å•æ—¶é—´'].dt.dayofweek
            df['ä¸‹å•æ—¥æœŸ'] = df['ä¸‹å•æ—¶é—´'].dt.date
            day_map = {0: 'å‘¨ä¸€', 1: 'å‘¨äºŒ', 2: 'å‘¨ä¸‰', 3: 'å‘¨å››', 4: 'å‘¨äº”', 5: 'å‘¨å…­', 6: 'å‘¨æ—¥'}
            df['æ˜ŸæœŸåç§°'] = df['æ˜ŸæœŸå‡ '].map(day_map)
            
            # åªä¿ç•™å·²å®Œæˆçš„è®¢å•ç”¨äºåˆ†æï¼ˆé™é»˜å¤„ç†ï¼‰
            if 'è®¢å•çŠ¶æ€' in df.columns:
                completed_orders = df[df['è®¢å•çŠ¶æ€'] == 'å·²å®Œæˆ'].copy()
                return completed_orders
            else:
                return df
                
        except Exception as e:
            st.error(f"âš  è®¢å•æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
            return None
    
    @staticmethod
    @st.cache_data  
    def load_user_profiles():
        """åŠ è½½ç”¨æˆ·ç”»åƒæ•°æ®"""
        try:
            possible_paths = [
                r"D:\ç¼–ç¨‹\Uå›¢å›¢\user_profiles.csv",
                'user_profiles.csv',
                './user_profiles.csv',
                'data/user_profiles.csv', 
                './data/user_profiles.csv'
            ]
            
            for path in possible_paths:
                try:
                    if os.path.exists(path):
                        df = pd.read_csv(path, encoding='utf-8-sig')
                        return df
                except Exception as e:
                    continue
            
            return None
            
        except Exception as e:
            return None
    
    @staticmethod
    def generate_realistic_transaction_data(df):
        """ç”Ÿæˆæ›´ç¬¦åˆçœŸå®æƒ…å†µçš„äº¤æ˜“ç¯®æ•°æ®"""
        if df is None or len(df) == 0:
            return []
            
        transactions = []
        
        # ç­–ç•¥1ï¼šæŒ‰ç”¨æˆ·+æ—¥æœŸåˆ†ç»„ï¼Œæ¨¡æ‹ŸçœŸå®çš„æ¯æ—¥è´­ç‰©è¡Œä¸º
        df['è´­ç‰©æ—¥æœŸ'] = df['ä¸‹å•æ—¶é—´'].dt.date
        user_date_groups = df.groupby(['ç”¨æˆ·ID', 'è´­ç‰©æ—¥æœŸ'])
        
        for (user_id, date), group in user_date_groups:
            items = group['å•†å“åç§°'].unique().tolist()
            # ä¸è®ºå•å•†å“è¿˜æ˜¯å¤šå•†å“éƒ½ä¿ç•™ï¼Œè¿™æ›´ç¬¦åˆçœŸå®æƒ…å†µ
            transactions.append(items)
        
        # ç­–ç•¥2ï¼šæŒ‰ç”¨æˆ·+å°æ—¶åˆ†ç»„ï¼Œæ•æ‰çŸ­æ—¶é—´å†…çš„è´­ä¹°è¡Œä¸º
        df['è´­ç‰©å°æ—¶'] = df['ä¸‹å•æ—¶é—´'].dt.floor('H')
        hour_groups = df.groupby(['ç”¨æˆ·ID', 'è´­ç‰©å°æ—¶'])
        
        for (user_id, hour), group in hour_groups:
            items = group['å•†å“åç§°'].unique().tolist()
            # é¿å…é‡å¤æ·»åŠ ç›¸åŒçš„äº¤æ˜“
            if items not in transactions:
                transactions.append(items)
        
        # ç­–ç•¥3ï¼šåŸºäºç”¨æˆ·æ•´ä½“è´­ä¹°å†å²ï¼ˆé™ä½æƒé‡ï¼Œé¿å…è¿‡åº¦å½±å“ï¼‰
        user_groups = df.groupby('ç”¨æˆ·ID')
        for user_id, group in user_groups:
            items = group['å•†å“åç§°'].unique().tolist()
            # åªæœ‰è´­ä¹°äº†3ç§ä»¥ä¸Šå•†å“çš„ç”¨æˆ·æ‰ä½œä¸ºä¸€ä¸ªæ•´ä½“ç¯®å­ï¼Œä¸”æƒé‡è¾ƒä½
            if len(items) >= 3:
                # åªæ·»åŠ ä¸€æ¬¡ï¼Œé¿å…è¿‡åº¦å½±å“
                transactions.append(items)
        
        # ç­–ç•¥4ï¼šé€‚åº¦æ·»åŠ ä¸€äº›å¸¸è§çš„ç»„åˆï¼Œä½†ä¸è¦è¿‡å¤šå½±å“çœŸå®æ€§
        common_combinations = [
            ['è‹¹æœ', 'é¦™è•‰'],
            ['è‰è“', 'è‘¡è„'],
            ['æ©˜å­', 'æ¢¨'],
            ['è‹¹æœ', 'æ©˜å­'],
            ['é¦™è•‰', 'è‰è“']
        ]
        
        available_products = df['å•†å“åç§°'].unique().tolist()
        for combo in common_combinations:
            if all(item in available_products for item in combo):
                # åªæ·»åŠ å°‘é‡æ¬¡æ•°ï¼Œä¿æŒçœŸå®æ€§
                transactions.append(combo)
        
        return transactions

class DataAnalyzer:
    """æ•°æ®åˆ†æå™¨ç±»"""
    
    @staticmethod
    def create_basic_visualizations(df):
        """åˆ›å»ºåŸºç¡€å¯è§†åŒ–å›¾è¡¨"""
        if df is None or len(df) == 0:
            st.error("âš  æ²¡æœ‰å¯ç”¨æ•°æ®è¿›è¡Œåˆ†æ")
            return None, None, None, None
            
        # 1. çƒ­é—¨æ°´æœé”€é‡åˆ†æ
        product_sales = df.groupby('å•†å“åç§°').agg({
            'è´­ä¹°æ•°é‡': 'sum',
            'è®¢å•é‡‘é¢': 'sum'
        }).reset_index().sort_values('è´­ä¹°æ•°é‡', ascending=True)
        
        fig1 = px.bar(
            product_sales,
            x='è´­ä¹°æ•°é‡', y='å•†å“åç§°', orientation='h',
            title='ğŸ† çƒ­é—¨å•†å“æ’è¡Œæ¦œï¼ˆæŒ‰æ€»é”€é‡ï¼‰',
            color='è´­ä¹°æ•°é‡',
            color_continuous_scale='viridis',
            text='è´­ä¹°æ•°é‡'
        )
        fig1.update_layout(
            height=400,
            title_font_size=18,
            title_x=0.5,
            showlegend=False,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        fig1.update_traces(texttemplate='%{text}ä»¶', textposition='outside')
        
        # 2. å„å°æ—¶è®¢å•é‡åˆ†å¸ƒ
        hourly_orders = df.groupby('ä¸‹å•å°æ—¶')['è®¢å•ç¼–å·'].count().reset_index()
        fig2 = px.line(
            hourly_orders, x='ä¸‹å•å°æ—¶', y='è®¢å•ç¼–å·',
            title='â° å„å°æ—¶è®¢å•é‡åˆ†å¸ƒï¼ˆç”¨æˆ·è¡Œä¸ºåˆ†æï¼‰',
            markers=True
        )
        fig2.update_traces(line_color='#FF6B6B', line_width=4, marker_size=10)
        fig2.update_layout(
            height=400,
            title_font_size=18,
            title_x=0.5,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            xaxis_title="å°æ—¶",
            yaxis_title="è®¢å•æ•°é‡"
        )
        
        # 3. å„æ˜ŸæœŸé”€å”®é¢åˆ†æ
        weekday_order = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
        weekly_sales = df.groupby('æ˜ŸæœŸåç§°')['è®¢å•é‡‘é¢'].sum().reindex(weekday_order).reset_index()
        fig3 = px.bar(
            weekly_sales, x='æ˜ŸæœŸåç§°', y='è®¢å•é‡‘é¢',
            title='ğŸ“… å„æ˜ŸæœŸæ€»é”€å”®é¢ï¼ˆæ¶ˆè´¹ä¹ æƒ¯åˆ†æï¼‰',
            color='è®¢å•é‡‘é¢',
            color_continuous_scale='plasma',
            text='è®¢å•é‡‘é¢'
        )
        fig3.update_layout(
            height=400,
            title_font_size=18,
            title_x=0.5,
            showlegend=False,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        fig3.update_traces(texttemplate='Â¥%{text:.0f}', textposition='outside')
        
        # 4. æ ¡åŒºé”€å”®é¢å¯¹æ¯”
        if 'æ ¡åŒº' in df.columns:
            campus_sales = df.groupby('æ ¡åŒº')['è®¢å•é‡‘é¢'].sum().reset_index()
            fig4 = px.pie(
                campus_sales, values='è®¢å•é‡‘é¢', names='æ ¡åŒº',
                title='ğŸ« å„æ ¡åŒºé”€å”®é¢åˆ†å¸ƒ',
                color_discrete_sequence=px.colors.qualitative.Set3
            )
            fig4.update_traces(textposition='inside', textinfo='percent+label')
            fig4.update_layout(
                height=400,
                title_font_size=18,
                title_x=0.5
            )
        else:
            fig4 = px.scatter(x=[1], y=[1], title="æ ¡åŒºæ•°æ®ä¸å¯ç”¨")
        
        return fig1, fig2, fig3, fig4
    
    @staticmethod
    def association_rules_analysis(transactions):
        """å…³è”è§„åˆ™åˆ†æ - ä¼˜åŒ–å‚æ•°ä»¥å‘ç°åˆç†çš„å…³è”è§„åˆ™"""
        if len(transactions) < 3:
            return pd.DataFrame(), pd.DataFrame()
            
        try:
            # æ•°æ®è½¬æ¢
            te = TransactionEncoder()
            te_ary = te.fit(transactions).transform(transactions)
            df_onehot = pd.DataFrame(te_ary, columns=te.columns_)
            
            # åŠ¨æ€è°ƒæ•´æœ€å°æ”¯æŒåº¦é˜ˆå€¼
            # æ ¹æ®äº¤æ˜“æ•°é‡è‡ªé€‚åº”è°ƒæ•´ï¼Œç¡®ä¿èƒ½å‘ç°å…³è”
            if len(transactions) <= 20:
                min_support = max(0.15, 2/len(transactions))  # å°æ•°æ®é›†ç”¨è¾ƒé«˜é˜ˆå€¼
            elif len(transactions) <= 50:
                min_support = max(0.08, 3/len(transactions))  # ä¸­ç­‰æ•°æ®é›†
            else:
                min_support = max(0.03, 5/len(transactions))  # å¤§æ•°æ®é›†ç”¨è¾ƒä½é˜ˆå€¼
            
            frequent_itemsets = apriori(df_onehot, min_support=min_support, use_colnames=True)
            
            # å¦‚æœæ²¡æœ‰å‘ç°é¢‘ç¹é¡¹é›†ï¼Œè¿›ä¸€æ­¥é™ä½é˜ˆå€¼
            if len(frequent_itemsets) <= 1:
                min_support = max(0.02, 2/len(transactions))
                frequent_itemsets = apriori(df_onehot, min_support=min_support, use_colnames=True)
            
            if len(frequent_itemsets) > 1:
                # ç”Ÿæˆå…³è”è§„åˆ™ - ä½¿ç”¨è¾ƒä½çš„ç½®ä¿¡åº¦é˜ˆå€¼
                try:
                    rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.1)
                    rules = rules[(rules['lift'] >= 1.0)]  # åªä¿ç•™æœ‰æ­£é¢å…³è”çš„è§„åˆ™
                    
                    # å¦‚æœè§„åˆ™å¤ªå°‘ï¼Œè¿›ä¸€æ­¥é™ä½é˜ˆå€¼
                    if len(rules) == 0:
                        rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.05)
                        rules = rules[(rules['lift'] >= 0.8)]  # ç¨å¾®æ”¾å®½æå‡åº¦è¦æ±‚
                    
                    # æŒ‰æå‡åº¦æ’åº
                    rules = rules.sort_values('lift', ascending=False)
                    
                    return frequent_itemsets, rules
                except Exception as inner_e:
                    # å¦‚æœç”Ÿæˆè§„åˆ™å¤±è´¥ï¼Œè¿”å›é¢‘ç¹é¡¹é›†
                    return frequent_itemsets, pd.DataFrame()
            else:
                return frequent_itemsets, pd.DataFrame()
        except Exception as e:
            st.error(f"å…³è”è§„åˆ™åˆ†æå¤±è´¥: {e}")
            return pd.DataFrame(), pd.DataFrame()
    
    @staticmethod
    def customer_segmentation(df):
        """å®¢æˆ·åˆ†ç¾¤åˆ†æ"""
        try:
            # ç”ŸæˆRFMæ•°æ®
            snapshot_date = df['ä¸‹å•æ—¶é—´'].max() + timedelta(days=1)
            
            rfm_df = df.groupby('ç”¨æˆ·ID').agg({
                'ä¸‹å•æ—¶é—´': lambda x: (snapshot_date - x.max()).days,
                'è®¢å•ç¼–å·': 'count',
                'è®¢å•é‡‘é¢': 'sum'
            })
            
            rfm_df.rename(columns={
                'ä¸‹å•æ—¶é—´': 'Recency',
                'è®¢å•ç¼–å·': 'Frequency', 
                'è®¢å•é‡‘é¢': 'Monetary'
            }, inplace=True)
            
            # æ•°æ®æ ‡å‡†åŒ–
            scaler = StandardScaler()
            rfm_scaled = scaler.fit_transform(rfm_df)
            
            # K-meansèšç±»
            kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
            clusters = kmeans.fit_predict(rfm_scaled)
            rfm_df['Cluster'] = clusters
            
            # è®¡ç®—èšç±»ä¸­å¿ƒ
            cluster_centers = kmeans.cluster_centers_
            cluster_centers_original = scaler.inverse_transform(cluster_centers)
            
            return rfm_df, cluster_centers_original
        except Exception as e:
            st.error(f"å®¢æˆ·åˆ†ç¾¤åˆ†æå¤±è´¥: {e}")
            return pd.DataFrame(), np.array([])

def main():
    """ä¸»å‡½æ•°"""
    
    # é¡µé¢æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸ›’ Uå›¢å›¢æ ¡å›­å›¢è´­æ™ºèƒ½åˆ†æç³»ç»Ÿ</h1>', unsafe_allow_html=True)
    
    # æ•°æ®æ¥æºè¯´æ˜ - ç®€åŒ–ç‰ˆ
    st.markdown("""
    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                padding: 20px; border-radius: 15px; margin-bottom: 30px; color: white;">
        <div style="display: flex; align-items: center;">
            <div style="font-size: 3rem; margin-right: 20px;">ğŸ“Š</div>
            <div>
                <h3 style="margin: 0; color: white;">æ•°æ®é©±åŠ¨çš„æ ¡å›­å›¢è´­æ™ºèƒ½åˆ†æ</h3>
                <p style="margin: 5px 0; opacity: 0.9;">åŸºäºçœŸå®å°ç¨‹åºåå°æ•°æ®ï¼Œæ·±åº¦æŒ–æ˜ç”¨æˆ·è¡Œä¸ºæ¨¡å¼ï¼Œä¼˜åŒ–è¿è¥ç­–ç•¥</p>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # ä¾§è¾¹æ 
    st.sidebar.title("ğŸ“Š åˆ†ææ¨¡å—é€‰æ‹©")
    analysis_type = st.sidebar.selectbox(
        "è¯·é€‰æ‹©è¦å±•ç¤ºçš„åˆ†ææ¨¡å—ï¼š",
        ["ğŸ“ˆ ç”¨æˆ·è¡Œä¸ºæ•°æ®å¯è§†åŒ–", "ğŸ”— å…³è”è§„åˆ™æŒ–æ˜ä¸æ¨è", "ğŸ‘¥ ç”¨æˆ·åˆ†ç¾¤ä¸è¥é”€ç­–ç•¥", "ğŸ“‹ ç»¼åˆæŠ¥å‘Š"]
    )
    
    # åŠ è½½æ•°æ® - é™é»˜åŠ è½½ï¼Œåªåœ¨å¤±è´¥æ—¶æ˜¾ç¤ºé”™è¯¯
    df = DataLoader.load_orders_data()
    user_profiles = DataLoader.load_user_profiles()
    
    if df is None:
        st.error("âš  æ•°æ®åŠ è½½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­åˆ†æ")
        st.info("ğŸ’¡ è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨å¹¶æ ¼å¼æ­£ç¡®")
        return
    
    # æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆï¼ˆç®€åŒ–ç‰ˆï¼‰
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“Š æ•°æ®æ¦‚è§ˆ")
    
    # ä½¿ç”¨æ›´ç¾è§‚çš„metrics
    total_orders = len(df)
    active_users = df['ç”¨æˆ·ID'].nunique()
    total_revenue = df['è®¢å•é‡‘é¢'].sum()
    avg_order_value = df['è®¢å•é‡‘é¢'].mean()
    
    st.sidebar.metric("ğŸ“¦ æ€»è®¢å•æ•°", f"{total_orders:,}")
    st.sidebar.metric("ğŸ‘¤ æ´»è·ƒç”¨æˆ·", f"{active_users:,}")
    st.sidebar.metric("ğŸ’° æ€»é”€å”®é¢", f"Â¥{total_revenue:,.0f}")
    st.sidebar.metric("ğŸ“Š å¹³å‡å®¢å•ä»·", f"Â¥{avg_order_value:.2f}")
    
    # æ•°æ®æ—¶é—´èŒƒå›´
    st.sidebar.markdown("### ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´")
    st.sidebar.write(f"ğŸŸ¢ å¼€å§‹ï¼š{df['ä¸‹å•æ—¶é—´'].min().strftime('%Y-%m-%d')}")
    st.sidebar.write(f"ğŸ”´ ç»“æŸï¼š{df['ä¸‹å•æ—¶é—´'].max().strftime('%Y-%m-%d')}")
    
    # æ ¹æ®é€‰æ‹©æ˜¾ç¤ºä¸åŒçš„åˆ†ææ¨¡å—
    if analysis_type == "ğŸ“ˆ ç”¨æˆ·è¡Œä¸ºæ•°æ®å¯è§†åŒ–":
        show_data_visualization(df)
    elif analysis_type == "ğŸ”— å…³è”è§„åˆ™æŒ–æ˜ä¸æ¨è":
        # ä½¿ç”¨ä¿®æ­£åçš„äº¤æ˜“æ•°æ®ç”Ÿæˆ
        transactions = DataLoader.generate_realistic_transaction_data(df)
        show_association_rules(transactions)
    elif analysis_type == "ğŸ‘¥ ç”¨æˆ·åˆ†ç¾¤ä¸è¥é”€ç­–ç•¥":
        show_customer_segmentation(df)
    elif analysis_type == "ğŸ“‹ ç»¼åˆæŠ¥å‘Š":
        transactions = DataLoader.generate_realistic_transaction_data(df)
        show_comprehensive_report(df, transactions, user_profiles)

def show_data_visualization(df):
    """æ˜¾ç¤ºæ•°æ®å¯è§†åŒ–æ¨¡å—"""
    st.markdown('<h2 class="sub-header">ğŸ“ˆ ç”¨æˆ·è¡Œä¸ºæ•°æ®å¯è§†åŒ–</h2>', unsafe_allow_html=True)
    
    # åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
    fig1, fig2, fig3, fig4 = DataAnalyzer.create_basic_visualizations(df)
    
    if fig1 is None:
        return
    
    # å¸ƒå±€å±•ç¤º
    col1, col2 = st.columns(2)
    
    with col1:
        st.plotly_chart(fig1, use_container_width=True)
        st.plotly_chart(fig3, use_container_width=True)
    
    with col2:
        st.plotly_chart(fig2, use_container_width=True)
        st.plotly_chart(fig4, use_container_width=True)
    
    # æ•°æ®æ´å¯Ÿ
    st.markdown('<div class="insight-box">', unsafe_allow_html=True)
    st.markdown("### ğŸ’¡ æ•°æ®æ´å¯Ÿ")
    
    # è®¡ç®—å…³é”®æŒ‡æ ‡
    top_fruit = df.groupby('å•†å“åç§°')['è´­ä¹°æ•°é‡'].sum().idxmax()
    top_fruit_sales = df.groupby('å•†å“åç§°')['è´­ä¹°æ•°é‡'].sum().max()
    peak_hour = df.groupby('ä¸‹å•å°æ—¶')['è®¢å•ç¼–å·'].count().idxmax()
    peak_hour_orders = df.groupby('ä¸‹å•å°æ—¶')['è®¢å•ç¼–å·'].count().max()
    best_day = df.groupby('æ˜ŸæœŸåç§°')['è®¢å•é‡‘é¢'].sum().idxmax()
    
    st.write(f"- **æœ€å—æ¬¢è¿å•†å“**ï¼š{top_fruit}ï¼ˆé”€é‡{top_fruit_sales}ä»½ï¼‰")
    st.write(f"- **è®¢å•é«˜å³°æ—¶æ®µ**ï¼š{peak_hour}ç‚¹ï¼ˆ{peak_hour_orders}å•ï¼‰")
    st.write(f"- **é”€å”®æœ€ä½³æ—¥æœŸ**ï¼š{best_day}")
    st.write(f"- **å¹³å‡å®¢å•ä»·**ï¼šÂ¥{df['è®¢å•é‡‘é¢'].mean():.2f}")
    st.write(f"- **å¤è´­ç”¨æˆ·æ¯”ä¾‹**ï¼š{(df.groupby('ç”¨æˆ·ID')['è®¢å•ç¼–å·'].count() > 1).mean():.1%}")
    st.markdown('</div>', unsafe_allow_html=True)

def show_association_rules(transactions):
    """æ˜¾ç¤ºå…³è”è§„åˆ™åˆ†ææ¨¡å— - æ”¹è¿›ç‰ˆ"""
    st.markdown('<h2 class="sub-header">ğŸ”— å…³è”è§„åˆ™æŒ–æ˜ä¸æ¨è</h2>', unsafe_allow_html=True)
    
    # æ·»åŠ è¯´æ˜å¡ç‰‡
    st.markdown("""
    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                padding: 20px; border-radius: 15px; margin-bottom: 20px; color: white;">
        <h4 style="margin: 0; color: white;">ğŸ’¡ æ™ºèƒ½æ¨èç³»ç»Ÿ</h4>
        <p style="margin: 5px 0; opacity: 0.9;">é€šè¿‡åˆ†æç”¨æˆ·è´­ä¹°è¡Œä¸ºï¼Œå‘ç°å•†å“é—´çš„å…³è”å…³ç³»ï¼Œä¸ºç²¾å‡†è¥é”€æä¾›æ•°æ®æ”¯æŒ</p>
    </div>
    """, unsafe_allow_html=True)
    
    # äº¤æ˜“ç¯®ç»Ÿè®¡ - ä¿®æ­£ç‰ˆ
    if len(transactions) > 0:
        # è®¡ç®—æ›´çœŸå®çš„ç»Ÿè®¡æ•°æ®
        single_item_transactions = sum(1 for t in transactions if len(t) == 1)
        multi_item_transactions = sum(1 for t in transactions if len(t) > 1)
        total_transactions = len(transactions)
        
        transaction_stats = {
            'æ€»äº¤æ˜“ç¯®æ•°': total_transactions,
            'å¹³å‡ç¯®å­å¤§å°': round(sum(len(t) for t in transactions) / len(transactions), 2),
            'æœ€å¤§ç¯®å­å¤§å°': max(len(t) for t in transactions) if transactions else 0,
            'å¤šå•†å“äº¤æ˜“å æ¯”': f"{(multi_item_transactions / total_transactions * 100):.1f}%"
        }
        
        # ä½¿ç”¨cardså±•ç¤ºç»Ÿè®¡ä¿¡æ¯
        cols = st.columns(4)
        for i, (key, value) in enumerate(transaction_stats.items()):
            with cols[i]:
                st.markdown(f"""
                <div style="background: white; padding: 15px; border-radius: 10px; 
                           border-left: 4px solid #ff6b6b; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                    <h4 style="margin: 0; color: #333; font-size: 14px;">{key}</h4>
                    <p style="margin: 5px 0 0 0; font-size: 24px; font-weight: bold; color: #ff6b6b;">{value}</p>
                </div>
                """, unsafe_allow_html=True)
    
    # è¿›è¡Œå…³è”è§„åˆ™åˆ†æ
    frequent_itemsets, rules = DataAnalyzer.association_rules_analysis(transactions)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("### ğŸ“Š é¢‘ç¹é¡¹é›†åˆ†æ")
        if not frequent_itemsets.empty:
            # ç¾åŒ–é¢‘ç¹é¡¹é›†å±•ç¤º
            frequent_display = frequent_itemsets.copy()
            frequent_display['å•†å“ç»„åˆ'] = frequent_display['itemsets'].apply(
                lambda x: ' + '.join(list(x))
            )
            frequent_display['æ”¯æŒåº¦'] = (frequent_display['support'] * 100).round(1)
            frequent_display = frequent_display[['å•†å“ç»„åˆ', 'æ”¯æŒåº¦']].sort_values('æ”¯æŒåº¦', ascending=False)
            
            # åˆ›å»ºæ¡å½¢å›¾
            if len(frequent_display) > 0:
                fig_freq = px.bar(
                    frequent_display.head(10), 
                    x='æ”¯æŒåº¦', y='å•†å“ç»„åˆ',
                    orientation='h',
                    title='çƒ­é—¨å•†å“ç»„åˆæ”¯æŒåº¦',
                    color='æ”¯æŒåº¦',
                    color_continuous_scale='Blues'
                )
                fig_freq.update_layout(
                    height=400,
                    showlegend=False,
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)'
                )
                st.plotly_chart(fig_freq, use_container_width=True)
            
            # å±•ç¤ºè¡¨æ ¼
            st.dataframe(
                frequent_display, 
                use_container_width=True,
                hide_index=True
            )
        else:
            st.markdown("""
            <div style="background: #fff3cd; border: 1px solid #ffeaa7; 
                       padding: 15px; border-radius: 8px; text-align: center;">
                <h4 style="color: #856404; margin: 0;">ğŸ“ˆ æ•°æ®æ´å¯Ÿ</h4>
                <p style="color: #856404; margin: 10px 0;">å½“å‰æ•°æ®ä¸­é¢‘ç¹é¡¹é›†è¾ƒå°‘ï¼Œå»ºè®®:</p>
                <ul style="color: #856404; text-align: left; margin: 0;">
                    <li>æ”¶é›†æ›´å¤šç”¨æˆ·ç»„åˆè´­ä¹°æ•°æ®</li>
                    <li>è®¾è®¡æ°´æœç»„åˆå¥—é¤ä¿ƒé”€æ´»åŠ¨</li>
                    <li>åˆ†æç”¨æˆ·è´­ä¹°åå¥½</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("### ğŸ¯ å…³è”è§„åˆ™å‘ç°")
        if not rules.empty and len(rules) > 0:
            # ç¾åŒ–å…³è”è§„åˆ™å±•ç¤º
            rules_display = rules.copy()
            rules_display['å‰ä»¶'] = rules_display['antecedents'].apply(lambda x: ' + '.join(list(x)))
            rules_display['åä»¶'] = rules_display['consequents'].apply(lambda x: ' + '.join(list(x)))
            rules_display['æ”¯æŒåº¦'] = (rules_display['support'] * 100).round(1)
            rules_display['ç½®ä¿¡åº¦'] = (rules_display['confidence'] * 100).round(1)
            rules_display['æå‡åº¦'] = rules_display['lift'].round(2)
            
            display_rules = rules_display[['å‰ä»¶', 'åä»¶', 'æ”¯æŒåº¦', 'ç½®ä¿¡åº¦', 'æå‡åº¦']].head(10)
            
            # å¯è§†åŒ–å…³è”è§„åˆ™
            if len(rules_display) > 0:
                fig_rules = px.scatter(
                    rules_display, 
                    x='æ”¯æŒåº¦', y='ç½®ä¿¡åº¦', 
                    size='æå‡åº¦', 
                    color='æå‡åº¦',
                    hover_data=['å‰ä»¶', 'åä»¶'],
                    title='å…³è”è§„åˆ™è´¨é‡åˆ†å¸ƒ',
                    color_continuous_scale='Viridis'
                )
                fig_rules.update_layout(
                    height=400,
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)'
                )
                st.plotly_chart(fig_rules, use_container_width=True)
            
            # å±•ç¤ºè§„åˆ™è¡¨æ ¼
            st.dataframe(
                display_rules, 
                use_container_width=True,
                hide_index=True
            )
            
            # æœ€ä½³æ¨èè§„åˆ™
            best_rule = rules.loc[rules['lift'].idxmax()]
            antecedent = ' + '.join(list(best_rule['antecedents']))
            consequent = ' + '.join(list(best_rule['consequents']))
            
            st.markdown(f"""
            <div style="background: linear-gradient(135deg, #43e97b 0%, #38f9d7 100%); 
                       padding: 15px; border-radius: 10px; margin-top: 15px;">
                <h4 style="color: white; margin: 0;">ğŸŒŸ æœ€å¼ºå…³è”æ¨è</h4>
                <p style="color: white; margin: 5px 0; font-size: 16px;">
                    è´­ä¹° <strong>{antecedent}</strong> â†’ æ¨è <strong>{consequent}</strong>
                </p>
                <p style="color: white; margin: 0; opacity: 0.9;">
                    ç½®ä¿¡åº¦: {best_rule['confidence']:.1%} | æå‡åº¦: {best_rule['lift']:.2f}å€
                </p>
            </div>
            """, unsafe_allow_html=True)
            
        else:
            st.markdown("""
            <div style="background: #f8f9fa; border-left: 4px solid #6c757d; 
                       padding: 15px; border-radius: 5px;">
                <h4 style="color: #495057; margin: 0;">ğŸ” å…³è”è§„åˆ™åˆ†æ</h4>
                <p style="color: #6c757d; margin: 10px 0;">æš‚æœªå‘ç°å¼ºå…³è”è§„åˆ™ï¼Œå¯èƒ½åŸå› ï¼š</p>
                <ul style="color: #6c757d; margin: 0;">
                    <li>ç”¨æˆ·å¤šä¸ºå•å“è´­ä¹°</li>
                    <li>å•†å“ç§ç±»ç›¸å¯¹ç‹¬ç«‹</li>
                    <li>éœ€è¦æ›´å¤šç»„åˆè´­ä¹°æ•°æ®</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
    
    # æ™ºèƒ½æ¨èç­–ç•¥
    st.markdown("### ğŸš€ æ™ºèƒ½è¥é”€ç­–ç•¥å»ºè®®")
    
    strategy_cols = st.columns(3)
    
    with strategy_cols[0]:
        st.markdown("""
        <div style="background: #e3f2fd; padding: 15px; border-radius: 10px; height: 200px;">
            <h4 style="color: #1976d2; margin: 0 0 10px 0;">ğŸ ç»„åˆå¥—é¤</h4>
            <ul style="color: #1976d2; margin: 0; font-size: 14px;">
                <li>è®¾è®¡æ°´æœæ‹¼ç›˜å¥—é¤</li>
                <li>å­£èŠ‚æ€§ç»„åˆæ¨è</li>
                <li>å¥åº·æ­é…å¥—é¤</li>
                <li>å­¦ç”Ÿä¼˜æƒ ç»„åˆ</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with strategy_cols[1]:
        st.markdown("""
        <div style="background: #f3e5f5; padding: 15px; border-radius: 10px; height: 200px;">
            <h4 style="color: #7b1fa2; margin: 0 0 10px 0;">ğŸ“± ä¸ªæ€§åŒ–æ¨è</h4>
            <ul style="color: #7b1fa2; margin: 0; font-size: 14px;">
                <li>åŸºäºå†å²è´­ä¹°æ¨è</li>
                <li>ç›¸ä¼¼ç”¨æˆ·åå¥½æ¨è</li>
                <li>èŠ‚æ—¥ç‰¹è‰²æ¨è</li>
                <li>æ–°å“è¯•åƒæ¨è</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with strategy_cols[2]:
        st.markdown("""
        <div style="background: #e8f5e8; padding: 15px; border-radius: 10px; height: 200px;">
            <h4 style="color: #388e3c; margin: 0 0 10px 0;">ğŸ’° ä¿ƒé”€ç­–ç•¥</h4>
            <ul style="color: #388e3c; margin: 0; font-size: 14px;">
                <li>æ»¡å‡ä¼˜æƒ æ´»åŠ¨</li>
                <li>ç¬¬äºŒä»¶åŠä»·</li>
                <li>ä¼šå‘˜ä¸“äº«æŠ˜æ‰£</li>
                <li>é™æ—¶ç§’æ€æ´»åŠ¨</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

def show_customer_segmentation(df):
    """æ˜¾ç¤ºå®¢æˆ·åˆ†ç¾¤åˆ†ææ¨¡å—"""
    st.markdown('<h2 class="sub-header">ğŸ‘¥ ç”¨æˆ·åˆ†ç¾¤ä¸è¥é”€ç­–ç•¥</h2>', unsafe_allow_html=True)
    
    # è¿›è¡Œå®¢æˆ·åˆ†ç¾¤åˆ†æ
    rfm_df, cluster_centers = DataAnalyzer.customer_segmentation(df)
    
    if rfm_df.empty:
        st.error("å®¢æˆ·åˆ†ç¾¤åˆ†æå¤±è´¥")
        return
    
    # RFMåˆ†æç»“æœ
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ“Š RFMåˆ†æç»“æœ")
        st.dataframe(rfm_df.head(10))
        
        # å„ç¾¤ä½“ç‰¹å¾
        cluster_summary = rfm_df.groupby('Cluster').agg({
            'Recency': 'mean',
            'Frequency': 'mean',
            'Monetary': 'mean'
        }).round(2)
        
        st.markdown("### ğŸ“ˆ å„ç¾¤ä½“ç‰¹å¾")
        st.dataframe(cluster_summary)
    
    with col2:
        # 3Dæ•£ç‚¹å›¾å±•ç¤ºèšç±»ç»“æœ
        fig_3d = px.scatter_3d(
            rfm_df, x='Recency', y='Frequency', z='Monetary',
            color='Cluster', title='ç”¨æˆ·RFMä¸‰ç»´åˆ†å¸ƒ',
            labels={'Recency': 'æœ€è¿‘è´­ä¹°å¤©æ•°', 'Frequency': 'è´­ä¹°é¢‘æ¬¡', 'Monetary': 'æ¶ˆè´¹é‡‘é¢'}
        )
        st.plotly_chart(fig_3d, use_container_width=True)
    
    # ç¾¤ä½“åˆ†æå’Œè¥é”€ç­–ç•¥
    st.markdown("### ğŸ¯ ç”¨æˆ·ç¾¤ä½“åˆ†æä¸è¥é”€ç­–ç•¥")
    
    # å®šä¹‰ç¾¤ä½“æ ‡ç­¾
    cluster_names = {
        0: "é«˜ä»·å€¼æ ¸å¿ƒç”¨æˆ·",
        1: "ä½ä»·å€¼/æµå¤±é£é™©ç”¨æˆ·", 
        2: "æ½œåŠ›ä»·å€¼ç”¨æˆ·",
        3: "æ–°ç”¨æˆ·/å‘å±•ç”¨æˆ·"
    }
    
    cluster_strategies = {
        0: "VIPä¸“å±æœåŠ¡ã€é™æ—¶ç‰¹ä»·ã€ä¼šå‘˜ç§¯åˆ†å¥–åŠ±",
        1: "å¬å›ä¼˜æƒ åˆ¸ã€æ»¡å‡æ´»åŠ¨ã€é‡æ–°æ¿€æ´»è¥é”€",
        2: "ä¸ªæ€§åŒ–æ¨èã€ç”Ÿæ—¥ä¼˜æƒ ã€å‡çº§å¼•å¯¼",
        3: "æ–°æ‰‹å¼•å¯¼ã€é¦–å•ä¼˜æƒ ã€åŸ¹å…»å¿ è¯šåº¦"
    }
    
    for cluster_id in range(4):
        if cluster_id in rfm_df['Cluster'].values:
            user_count = len(rfm_df[rfm_df['Cluster'] == cluster_id])
            percentage = user_count / len(rfm_df) * 100
            
            with st.expander(f"ğŸ” {cluster_names.get(cluster_id, f'ç¾¤ä½“{cluster_id}')} ({user_count}äºº, {percentage:.1f}%)"):
                col_a, col_b = st.columns(2)
                with col_a:
                    st.write("**ç¾¤ä½“ç‰¹å¾ï¼š**")
                    cluster_data = cluster_summary.loc[cluster_id]
                    st.write(f"- å¹³å‡è·ä¸Šæ¬¡è´­ä¹°ï¼š{cluster_data['Recency']:.1f}å¤©")
                    st.write(f"- å¹³å‡è´­ä¹°é¢‘æ¬¡ï¼š{cluster_data['Frequency']:.1f}æ¬¡")
                    st.write(f"- å¹³å‡æ¶ˆè´¹é‡‘é¢ï¼šÂ¥{cluster_data['Monetary']:.2f}")
                
                with col_b:
                    st.write("**è¥é”€ç­–ç•¥ï¼š**")
                    st.write(f"- {cluster_strategies.get(cluster_id, 'å¾…åˆ¶å®šç­–ç•¥')}")

def show_comprehensive_report(df, transactions, user_profiles):
    """æ˜¾ç¤ºç»¼åˆæŠ¥å‘Š"""
    st.markdown('<h2 class="sub-header">ğŸ“‹ Uå›¢å›¢é¡¹ç›®ç»¼åˆåˆ†ææŠ¥å‘Š</h2>', unsafe_allow_html=True)
    
    # é¡¹ç›®æ¦‚è¿° - æ›´åŠ ç¾è§‚
    st.markdown("""
    <div style="background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 50%, #fecfef 100%); 
                padding: 25px; border-radius: 20px; margin-bottom: 30px;">
        <h3 style="color: #2c3e50; margin: 0 0 15px 0; text-align: center;">ğŸ¯ é¡¹ç›®æ¦‚è¿°</h3>
        <p style="color: #34495e; font-size: 16px; line-height: 1.6; margin: 0; text-align: center;">
            <strong>Uå›¢å›¢æ ¡å›­å›¢è´­æ™ºèƒ½åˆ†æç³»ç»Ÿ</strong>åŸºäºçœŸå®çš„å°ç¨‹åºåå°æ•°æ®ï¼Œè¿ç”¨æœºå™¨å­¦ä¹ ç®—æ³•æ„å»ºçš„æ•°æ®åˆ†æå¹³å°ï¼Œ
            é€šè¿‡æ·±åº¦æŒ–æ˜ç”¨æˆ·è¡Œä¸ºæ¨¡å¼ï¼Œä¸ºæ ¡å›­å›¢è´­ä¸šåŠ¡æä¾›ç§‘å­¦çš„è¿è¥å†³ç­–æ”¯æŒã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # å…³é”®æ•°æ®æŒ‡æ ‡ - ä½¿ç”¨å¡ç‰‡å¸ƒå±€
    st.markdown("### ğŸ“Š æ ¸å¿ƒä¸šåŠ¡æŒ‡æ ‡")
    
    col1, col2, col3, col4 = st.columns(4)
    
    metrics_data = [
        ("ğŸ“¦", "æ€»è®¢å•æ•°", len(df), "#e74c3c"),
        ("ğŸ‘¥", "æ´»è·ƒç”¨æˆ·", df['ç”¨æˆ·ID'].nunique(), "#3498db"),
        ("ğŸ’°", "æ€»é”€å”®é¢", f"Â¥{df['è®¢å•é‡‘é¢'].sum():.0f}", "#27ae60"),
        ("ğŸ“Š", "å¹³å‡å®¢å•ä»·", f"Â¥{df['è®¢å•é‡‘é¢'].mean():.2f}", "#f39c12")
    ]
    
    for i, (icon, label, value, color) in enumerate(metrics_data):
        with [col1, col2, col3, col4][i]:
            st.markdown(f"""
            <div style="background: white; padding: 20px; border-radius: 15px; 
                       border-left: 5px solid {color}; box-shadow: 0 4px 6px rgba(0,0,0,0.1);
                       text-align: center; margin-bottom: 20px;">
                <div style="font-size: 2rem; margin-bottom: 10px;">{icon}</div>
                <h4 style="margin: 0; color: #2c3e50; font-size: 14px;">{label}</h4>
                <p style="margin: 10px 0 0 0; font-size: 24px; font-weight: bold; color: {color};">{value}</p>
            </div>
            """, unsafe_allow_html=True)
    
    # æ ¸å¿ƒå‘ç°
    st.markdown("### ğŸ” æ ¸å¿ƒå‘ç°")
    
    # è®¡ç®—å…³é”®æŒ‡æ ‡
    top_products = df.groupby('å•†å“åç§°')['è´­ä¹°æ•°é‡'].sum().sort_values(ascending=False).head(3)
    peak_hour = df.groupby('ä¸‹å•å°æ—¶')['è®¢å•ç¼–å·'].count().idxmax()
    repeat_customer_rate = (df.groupby('ç”¨æˆ·ID')['è®¢å•ç¼–å·'].count() > 1).mean()
    
    # è®¡ç®—çœŸå®çš„å¤šå•†å“äº¤æ˜“å æ¯”
    single_item_transactions = sum(1 for t in transactions if len(t) == 1)
    multi_item_transactions = sum(1 for t in transactions if len(t) > 1)
    total_transactions = len(transactions)
    multi_item_rate = multi_item_transactions / total_transactions if total_transactions > 0 else 0
    
    insights_cols = st.columns(2)
    
    with insights_cols[0]:
        st.markdown(f"""
        <div style="background: #f8f9ff; padding: 20px; border-radius: 15px; border-left: 5px solid #6c5ce7;">
            <h4 style="color: #6c5ce7; margin: 0 0 15px 0;">ğŸ“ˆ ä¸šåŠ¡æ´å¯Ÿ</h4>
            <ul style="color: #2d3436; line-height: 1.8; margin: 0;">
                <li><strong>çƒ­é”€å•†å“TOP3:</strong> {', '.join(top_products.index.tolist())}</li>
                <li><strong>è®¢å•é«˜å³°æ—¶æ®µ:</strong> {peak_hour}ç‚¹</li>
                <li><strong>å¤è´­ç”¨æˆ·å æ¯”:</strong> {repeat_customer_rate:.1%}</li>
                <li><strong>å¤šå•†å“äº¤æ˜“å æ¯”:</strong> {multi_item_rate:.1%}</li>
                <li><strong>æ•°æ®è¦†ç›–æœŸé—´:</strong> {(df['ä¸‹å•æ—¶é—´'].max() - df['ä¸‹å•æ—¶é—´'].min()).days}å¤©</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with insights_cols[1]:
        st.markdown("""
        <div style="background: #fff5f5; padding: 20px; border-radius: 15px; border-left: 5px solid #e17055;">
            <h4 style="color: #e17055; margin: 0 0 15px 0;">ğŸ’¡ æŠ€æœ¯äº®ç‚¹</h4>
            <ul style="color: #2d3436; line-height: 1.8; margin: 0;">
                <li><strong>Python + Streamlit</strong> æ„å»ºäº¤äº’å¼Webåº”ç”¨</li>
                <li><strong>Scikit-learn</strong> å®ç°æœºå™¨å­¦ä¹ ç®—æ³•</li>
                <li><strong>Plotly</strong> åˆ›å»ºåŠ¨æ€å¯è§†åŒ–å›¾è¡¨</li>
                <li><strong>MLxtend</strong> å®ç°å…³è”è§„åˆ™æŒ–æ˜</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    # æŠ€æœ¯å®ç°äº®ç‚¹
    st.markdown("### â­ æŠ€æœ¯å®ç°äº®ç‚¹")
    
    tech_cols = st.columns(2)
    
    with tech_cols[0]:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #74b9ff 0%, #0984e3 100%); 
                   padding: 20px; border-radius: 15px; color: white; margin-bottom: 20px;">
            <h4 style="color: white; margin: 0 0 15px 0;">ğŸ”§ æ ¸å¿ƒæŠ€æœ¯æ ˆ</h4>
            <ul style="color: white; opacity: 0.9; line-height: 1.6; margin: 0;">
                <li>Python + Streamlit æ„å»ºäº¤äº’å¼Webåº”ç”¨</li>
                <li>Scikit-learn å®ç°æœºå™¨å­¦ä¹ ç®—æ³•</li>
                <li>Plotly åˆ›å»ºåŠ¨æ€å¯è§†åŒ–å›¾è¡¨</li>
                <li>MLxtend å®ç°å…³è”è§„åˆ™æŒ–æ˜</li>
                <li>åŸºäºçœŸå®æ•°æ®çš„å®Œæ•´åˆ†ææµç¨‹</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with tech_cols[1]:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #fd79a8 0%, #e84393 100%); 
                   padding: 20px; border-radius: 15px; color: white; margin-bottom: 20px;">
            <h4 style="color: white; margin: 0 0 15px 0;">ğŸ’¡ ä¸šåŠ¡ä»·å€¼åˆ›æ–°</h4>
            <ul style="color: white; opacity: 0.9; line-height: 1.6; margin: 0;">
                <li>æ•°æ®é©±åŠ¨çš„è¿è¥å†³ç­–æ”¯æŒ</li>
                <li>ä¸ªæ€§åŒ–æ¨èæå‡ç”¨æˆ·ä½“éªŒ</li>
                <li>ç²¾å‡†è¥é”€ç­–ç•¥ä¼˜åŒ–è½¬åŒ–ç‡</li>
                <li>å¯æ‰©å±•çš„åˆ†ææ¡†æ¶è®¾è®¡</li>
                <li>å®Œæ•´çš„å•†ä¸šé—­ç¯æ€è€ƒ</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
